{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark123/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.cuda.nvtx as nvtx\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "torch.manual_seed(2244)\n",
    "\n",
    "from torch.utils.cpp_extension import load_inline, load\n",
    "\n",
    "# Define the CUDA kernel and C++ wrapper\n",
    "cuda_source = '''\n",
    "__global__ void square_matrix_kernel(const float* matrix, float* result, int width, int height) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (row < height && col < width) {\n",
    "        int idx = row * width + col;\n",
    "        result[idx] = matrix[idx] * matrix[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "torch::Tensor square_matrix(torch::Tensor matrix) {\n",
    "    const auto height = matrix.size(0);\n",
    "    const auto width = matrix.size(1);\n",
    "\n",
    "    auto result = torch::empty_like(matrix);\n",
    "\n",
    "    dim3 threads_per_block(16, 16);\n",
    "    dim3 number_of_blocks((width + threads_per_block.x - 1) / threads_per_block.x,\n",
    "                          (height + threads_per_block.y - 1) / threads_per_block.y);\n",
    "\n",
    "    square_matrix_kernel<<<number_of_blocks, threads_per_block>>>(\n",
    "        matrix.data_ptr<float>(), result.data_ptr<float>(), width, height);\n",
    "\n",
    "    return result;\n",
    "}\n",
    "'''\n",
    "\n",
    "cpp_source = \"torch::Tensor square_matrix(torch::Tensor matrix);\"\n",
    "\n",
    "# Load the CUDA kernel as a PyTorch extension\n",
    "square_matrix_extension = load_inline(\n",
    "    name='square_matrix_extension',\n",
    "    cpp_sources=cpp_source,\n",
    "    cuda_sources=cuda_source,\n",
    "    functions=['square_matrix'],\n",
    "    with_cuda=True,\n",
    "    extra_cuda_cflags=[\"-O2\"],\n",
    "    build_directory='./load_inline_cuda',\n",
    "    # extra_cuda_cflags=['--expt-relaxed-constexpr']\n",
    ")\n",
    "\n",
    "a = torch.tensor([[1., 2., 3.], [4., 5., 6.]], device='cuda')\n",
    "print(square_matrix_extension.square_matrix(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark123/Desktop/programming-projects/realtime-nn/.venv/lib/python3.12/site-packages/torch/utils/cpp_extension.py:2356: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cuda_source = '''\n",
    "#include <curand.h>\n",
    "\n",
    "__global__ void de_crossover_kernel(uint32_t NP, uint32_t CR, float F, uint32_t best_model, float* d_ptr, float* d_out_ptr, uint32_t size) {\n",
    "\tint id = blockIdx.x * blockDim.x + threadIdx.x; // candidate id\n",
    "\n",
    "\treturn;\n",
    "}\n",
    "\n",
    "std::vector<std::vector<torch::Tensor>> de_crossover_cuda(const std::vector<torch::Tensor>& layers, const std::vector<torch::Tensor>& biases, int64_t NP, double CR, double F, int64_t best_model) {\n",
    "\tuint32_t num_layers = layers.size();\n",
    "\tstd::vector<float*> layer_ptrs(num_layers), bias_ptrs(num_layers);\n",
    "\tstd::vector<torch::Tensor> out_layers(num_layers), out_biases(num_layers);\n",
    "\tstd::vector<float*> out_layer_ptrs(num_layers), out_bias_ptrs(num_layers);\n",
    "\n",
    "\tcurandGenerator_t gen;\n",
    "\tfloat* d_agent_ids;\n",
    "\tfloat* d_Rs;\n",
    "\tfloat* d_ris;\n",
    "\tint num_agents = NP * 3, num_Rs = NP, num_ris = NP * num_layers;\n",
    "\tcudaMalloc(&d_agent_ids, num_agents * sizeof(float));\n",
    "\tcudaMalloc(&d_Rs, num_Rs * sizeof(float));\n",
    "\tcudaMalloc(&d_ris, num_ris * sizeof(float));\n",
    "\tcurandCreateGenerator(&gen, CURAND_RNG_PSEUDO_DEFAULT);\n",
    "\tcurandSetPseudoRandomGeneratorSeed(gen, 1234ULL);\n",
    "\tcurandGenerateUniform(gen, d_agent_ids, num_agents);\n",
    "\tcurandGenerateUniform(gen, d_Rs, num_Rs);\n",
    "\tcurandGenerateUniform(gen, d_ris, num_ris);\n",
    "\n",
    "\tfor (int i = 0; i < num_layers; i++) {\n",
    "\t\ttorch::Tensor layer_contig = layers[i].contiguous();\n",
    "\t\ttorch::Tensor bias_contig = biases[i].contiguous();\n",
    "\t\tlayer_ptrs[i] = layer_contig.data_ptr<float>();\n",
    "\t\tbias_ptrs[i] = bias_contig.data_ptr<float>();\n",
    "\n",
    "\t\t//out_layers[i] = torch::empty(layer_contig.sizes(), layer_contig.options());\n",
    "\t\t//out_biases[i] = torch::empty(bias_contig.sizes(), bias_contig.options());\n",
    "\t\tout_layers[i] = torch::clone(layer_contig);\n",
    "\t\tout_biases[i] = torch::clone(bias_contig);\n",
    "\t\tout_layer_ptrs[i] = out_layers[i].data_ptr<float>();\n",
    "\t\tout_bias_ptrs[i] = out_biases[i].data_ptr<float>();\n",
    "\n",
    "\t\tde_crossover_kernel<<<max(1l, layer_contig.numel() / 64), 64>>>(NP, CR, F, best_model, layer_ptrs[i], out_layer_ptrs[i], layer_contig.numel() / NP);\n",
    "\t\tde_crossover_kernel<<<max(1l, bias_contig.numel() / 64), 64>>>(NP, CR, F, best_model, bias_ptrs[i], out_bias_ptrs[i], bias_contig.numel() / NP);\n",
    "\t\tstd::cout << \"layer \" << i << \" has \" << layer_contig.numel() / NP << \" parameters\" << std::endl;\n",
    "\t\tstd::cout << \"bias  \" << i << \" has \" << bias_contig.numel() / NP  << \" parameters\" << std::endl;\n",
    "\t}\n",
    "\n",
    "\treturn {out_layers, out_biases};\n",
    "}\n",
    "'''\n",
    "\n",
    "cpp_source = '''\n",
    "std::vector<std::vector<torch::Tensor>> de_crossover_cuda(const std::vector<torch::Tensor>& layers, const std::vector<torch::Tensor>& biases, int64_t NP, double CR, double F, int64_t best_model);\n",
    "'''\n",
    "\n",
    "# Load the CUDA kernel as a PyTorch extension\n",
    "diff_evo = load_inline(\n",
    "    name='diff_evo',\n",
    "    cpp_sources=cpp_source,\n",
    "    cuda_sources=cuda_source,\n",
    "    functions=['de_crossover_cuda'],\n",
    "    with_cuda=True,\n",
    "    extra_cuda_cflags=[\"-O2\", \"-lcurand\", \"-L/usr/local/cuda-12.8/lib64\"],\n",
    "    build_directory='./diff_evo_cuda',\n",
    "    # extra_cuda_cflags=['--expt-relaxed-constexpr']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0 has 4 parameters\n",
      "bias  0 has 4 parameters\n",
      "layer 1 has 32 parameters\n",
      "bias  1 has 8 parameters\n",
      "layer 2 has 32 parameters\n",
      "bias  2 has 4 parameters\n",
      "layer 3 has 4 parameters\n",
      "bias  3 has 1 parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[tensor([[[-0.4910],\n",
       "           [-0.3428],\n",
       "           [ 0.3403],\n",
       "           [ 0.2454]]], device='cuda:0'),\n",
       "  tensor([[[ 0.1328,  0.1092,  0.0089, -0.0714],\n",
       "           [-0.1598, -0.3723, -0.3269,  0.0864],\n",
       "           [ 0.1329, -0.2498, -0.4025, -0.4032],\n",
       "           [-0.2811, -0.4085,  0.2468, -0.1030],\n",
       "           [ 0.2206, -0.1965,  0.1573, -0.1556],\n",
       "           [-0.3421,  0.1321,  0.1740, -0.3913],\n",
       "           [ 0.0927,  0.3641, -0.2914,  0.3535],\n",
       "           [ 0.0736, -0.2476,  0.0117,  0.0873]]], device='cuda:0'),\n",
       "  tensor([[[ 0.0595, -0.3595, -0.1029,  0.2792, -0.1462, -0.1379, -0.2917,\n",
       "            -0.0768],\n",
       "           [ 0.3870,  0.0787, -0.3164,  0.1996,  0.3077, -0.0210,  0.3335,\n",
       "             0.1931],\n",
       "           [-0.2034,  0.3209,  0.1388, -0.0423, -0.2605, -0.1912, -0.2201,\n",
       "             0.1347],\n",
       "           [ 0.0992,  0.2161, -0.0762,  0.3090,  0.2396,  0.3116, -0.3415,\n",
       "            -0.0331]]], device='cuda:0'),\n",
       "  tensor([[[-1.1462, -0.9455,  1.0581, -0.6094]]], device='cuda:0')],\n",
       " [tensor([[[-0.7781],\n",
       "           [ 0.3958],\n",
       "           [-1.2049],\n",
       "           [ 0.0644]]], device='cuda:0'),\n",
       "  tensor([[[-0.0614],\n",
       "           [-0.0275],\n",
       "           [ 0.2955],\n",
       "           [-0.1988],\n",
       "           [ 0.8378],\n",
       "           [ 0.1495],\n",
       "           [-0.5563],\n",
       "           [ 0.4262]]], device='cuda:0'),\n",
       "  tensor([[[ 0.4247],\n",
       "           [ 0.0898],\n",
       "           [-0.1225],\n",
       "           [ 1.0571]]], device='cuda:0'),\n",
       "  tensor([[[2.1052]]], device='cuda:0')]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin1s = nn.init.kaiming_uniform_(torch.empty((1, 4, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "lin2s = nn.init.kaiming_uniform_(torch.empty((1, 8, 4), requires_grad=False).to(device, non_blocking=True))\n",
    "lin3s = nn.init.kaiming_uniform_(torch.empty((1, 4, 8), requires_grad=False).to(device, non_blocking=True))\n",
    "lin4s = nn.init.kaiming_uniform_(torch.empty((1, 1, 4), requires_grad=False).to(device, non_blocking=True))\n",
    "layers = [lin1s, lin2s, lin3s, lin4s]\n",
    "\n",
    "bias1 = nn.init.kaiming_uniform_(torch.empty((1, 4, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "bias2 = nn.init.kaiming_uniform_(torch.empty((1, 8, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "bias3 = nn.init.kaiming_uniform_(torch.empty((1, 4, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "bias4 = nn.init.kaiming_uniform_(torch.empty((1, 1, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "biases = [bias1, bias2, bias3, bias4]\n",
    "\n",
    "diff_evo.de_crossover_cuda(layers, biases, 1, 0.9, 0.8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[4., 5., 6.], [7., 8., 9.]], device='cuda')\n",
    "print(square_matrix_extension.square_matrix(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = [0.1, 1, 1.8, 2]\n",
    "\n",
    "def gaussian(x, mu):\n",
    "    return (1 / (0.3 * math.sqrt(2 * math.pi))) * (math.e ** ((-1/2) * (((x - mu) / 0.3)) ** 2))\n",
    "\n",
    "def gaussian_mixture(x):\n",
    "    return gaussian(x, theta[0]) + gaussian(x, theta[1]) + gaussian(x, theta[2]) + gaussian(x, theta[3])\n",
    "\n",
    "batch_size = 400000\n",
    "\n",
    "class DE_NN(nn.Module):\n",
    "    def __init__(self, NP, CR, F):\n",
    "        super(DE_NN, self).__init__()\n",
    "        lin1s = nn.init.kaiming_uniform_(torch.empty((NP, 4, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        lin2s = nn.init.kaiming_uniform_(torch.empty((NP, 8, 4), requires_grad=False).to(device, non_blocking=True))\n",
    "        lin3s = nn.init.kaiming_uniform_(torch.empty((NP, 4, 8), requires_grad=False).to(device, non_blocking=True))\n",
    "        lin4s = nn.init.kaiming_uniform_(torch.empty((NP, 1, 4), requires_grad=False).to(device, non_blocking=True))\n",
    "        self.layers = [lin1s, lin2s, lin3s, lin4s]\n",
    "        bias1 = nn.init.kaiming_uniform_(torch.empty((NP, 4, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        bias2 = nn.init.kaiming_uniform_(torch.empty((NP, 8, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        bias3 = nn.init.kaiming_uniform_(torch.empty((NP, 4, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        bias4 = nn.init.kaiming_uniform_(torch.empty((NP, 1, 1), requires_grad=False).to(device, non_blocking=True))\n",
    "        self.biases = [bias1, bias2, bias3, bias4]\n",
    "        self.NP = NP\n",
    "        self.CR = CR\n",
    "        self.F = F\n",
    "        self.min_l = torch.tensor(float('inf'))\n",
    "        self.best_model = 0\n",
    "    def forward_all(self, X, layers, biases):\n",
    "        # This is just bmm???\n",
    "        #M = torch.empty((NP, 8, batch_size)).to(device) # l, i, j\n",
    "        #for l in range(NP):\n",
    "        #    for i in range(8):\n",
    "        #        for j in range(batch_size):\n",
    "        #            total = 0\n",
    "        #            for k in range(4):\n",
    "        #                total += self.lin2s[l,i,k] * X[l,k,j]\n",
    "        #            total += self.bias2[l, i]\n",
    "        #            M[l,i,j] = total\n",
    "        #print(torch.sum(torch.relu(M)))\n",
    "        for i in range(len(layers) - 1):\n",
    "            X = torch.relu(torch.einsum('lik,lkj->lij', layers[i], X) + biases[i])\n",
    "        X = torch.einsum('lik,lkj->lij', layers[len(layers) - 1], X) + biases[len(layers) - 1]\n",
    "        return X\n",
    "    def forward(self, X):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            X = torch.relu(torch.matmul(self.layers[i][self.best_model], X) + self.biases[i][self.best_model])\n",
    "        return torch.matmul(self.layers[len(self.layers) - 1][self.best_model], X) + self.biases[len(self.layers) - 1][self.best_model]\n",
    "    def step(self, X, Y, L, type='param'): # forward pass with candidate i\n",
    "        nvtx.range_push(\"forward_1\")\n",
    "        fx = L(self.forward_all(X, self.layers, self.biases), Y).mean(dim = 2)\n",
    "        nvtx.range_pop()\n",
    "        nvtx.range_push(f\"copy layers\")\n",
    "        y_layers = [self.layers[i].detach().clone() for i in range(len(self.layers))]\n",
    "        y_biases = [self.biases[i].detach().clone() for i in range(len(self.layers))]\n",
    "        nvtx.range_pop()\n",
    "        \n",
    "        for id in range(self.NP):\n",
    "            agent_ids = random.sample(range(0, self.NP), 3) # how to efficiently reject self? rej sampling?\n",
    "            R = random.randint(0, len(self.layers))\n",
    "            nvtx.range_push(f\"updating candidate {id}\")\n",
    "            for i in range(len(self.layers)):\n",
    "                nvtx.range_push(f\"updating layer {i}\")\n",
    "                ri = random.random()\n",
    "                if ri < self.CR or i == R:\n",
    "                    y_layers[i][id].copy_(self.layers[i][id] + self.F * (self.layers[i][self.best_model] - self.layers[i][id]) \n",
    "                    + self.F * (self.layers[i][agent_ids[0]] - self.layers[i][agent_ids[1]]))\n",
    "                    y_biases[i][id].copy_(self.biases[i][id] + self.F * (self.biases[i][self.best_model] - self.biases[i][id]) \n",
    "                    + self.F * (self.biases[i][agent_ids[0]] - self.biases[i][agent_ids[1]]))\n",
    "                #y_layers[i][id] *= 0.99\n",
    "                nvtx.range_pop()\n",
    "            nvtx.range_pop()\n",
    "\n",
    "        nvtx.range_push(\"forward_2\")\n",
    "        fy = L(self.forward_all(X, y_layers, y_biases), Y).mean(dim = 2)\n",
    "        nvtx.range_pop()\n",
    "\n",
    "        for id in range(self.NP):\n",
    "            nvtx.range_push(f\"updating model {id}\")\n",
    "            if fy[id] <= fx[id]:\n",
    "                for i in range(len(self.layers)):\n",
    "                    self.layers[i][id].copy_(y_layers[i][id])\n",
    "                    self.biases[i][id].copy_(y_biases[i][id])\n",
    "                fx[id] = fy[id]\n",
    "            if fx[id] < self.min_l:\n",
    "                self.best_model = id\n",
    "                self.min_l = fx[id]\n",
    "            nvtx.range_pop()\n",
    "        # what if we update layers on the CPU, the transfer it to the GPU so we dont incur costs for launching small kernels\n",
    "        # what if we iteratively compute the forward loss instead of waiting for everything to finish just to hide latency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2000\n",
    "\n",
    "NP = 44\n",
    "CR = 0.9\n",
    "F = 0.8\n",
    "X = torch.rand(1, batch_size).to(device) * 5 - 1\n",
    "Y = gaussian_mixture(X).to(device)\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "X = X.unsqueeze(0).expand(NP, 1, batch_size)\n",
    "Y = Y.unsqueeze(0).expand(NP, 1, batch_size)\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "model = DE_NN(NP, CR, F).to(device) \n",
    "model = torch.compile(model, mode='default')\n",
    "L = nn.MSELoss(reduction='none')\n",
    "\n",
    "Y_pred = model.forward_all(X, model.layers, model.biases)\n",
    "print(Y_pred.shape)\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.step(X, Y, L, 'block')\n",
    "    if e % 5 == 0:\n",
    "        with torch.no_grad():\n",
    "            test_X = torch.linspace(-1, 3, 1000).unsqueeze(0)\n",
    "            test_Y = gaussian_mixture(test_X)\n",
    "            model_Y = model(test_X.to(device)).cpu()\n",
    "            # Clear the previous output before plotting\n",
    "            clear_output(wait=True)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(test_X.numpy()[0], test_Y.numpy()[0], label='Gaussian Mixture')\n",
    "            plt.plot(test_X.numpy()[0], model_Y.numpy()[0], label='Predictions', color='red', linestyle='dotted')\n",
    "            plt.title(f'Gaussian Mixture Plot {model.min_l.item()}')\n",
    "            plt.xlabel('X')\n",
    "            plt.ylabel('Y')\n",
    "            plt.grid(True)\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
