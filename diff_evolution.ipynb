{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26d32d91bb0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import copy\n",
    "from statistics import mean\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "torch.manual_seed(1122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = [0.1, 1, 1.8, 2]\n",
    "\n",
    "def gaussian(x, mu):\n",
    "    return (1 / (0.3 * math.sqrt(2 * math.pi))) * (math.e ** ((-1/2) * (((x - mu) / 0.3)) ** 2))\n",
    "\n",
    "def gaussian_mixture(x):\n",
    "    return gaussian(x, theta[0]) + gaussian(x, theta[1]) + gaussian(x, theta[2]) + gaussian(x, theta[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DE_NN(nn.Module):\n",
    "    def __init__(self, NP, CR, F):\n",
    "        super(DE_NN, self).__init__()\n",
    "        lin1s = nn.ModuleList([nn.Linear(1, 4) for i in range(NP)])\n",
    "        lin2s = nn.ModuleList([nn.Linear(4, 8) for i in range(NP)])\n",
    "        lin3s = nn.ModuleList([nn.Linear(8, 4) for i in range(NP)])\n",
    "        lin4s = nn.ModuleList([nn.Linear(4, 1) for i in range(NP)])\n",
    "        self.layers = nn.ModuleList([lin1s, lin2s, lin3s, lin4s])\n",
    "        ranges1 = [range(dim_size) for dim_size in lin1s[0].weight.shape]\n",
    "        ranges2 = [range(dim_size) for dim_size in lin2s[0].weight.shape]\n",
    "        ranges3 = [range(dim_size) for dim_size in lin3s[0].weight.shape]\n",
    "        ranges4 = [range(dim_size) for dim_size in lin4s[0].weight.shape]\n",
    "        self.idxs = [list(itertools.product(*ranges1)), list(itertools.product(*ranges2)), list(itertools.product(*ranges3)), list(itertools.product(*ranges4))]\n",
    "        \n",
    "        self.NP = NP\n",
    "        self.CR = CR\n",
    "        self.F = F\n",
    "    def forward_i(self, X, layers): # a single pass\n",
    "        for k in range(len(layers) - 1):\n",
    "            X = torch.relu(layers[k](X))\n",
    "        return layers[len(layers) - 1](X)\n",
    "    def print_id(self, id, obj):\n",
    "        if id == 0:\n",
    "            print(obj)\n",
    "    def step(self, id, X, Y, L): # forward pass with candidate i\n",
    "        fx = L(self.forward_i(X, [l[id] for l in self.layers]), Y)\n",
    "        agent_ids = random.sample(range(0, self.NP), 3) # how to efficiently reject self?\n",
    "        y = [copy.deepcopy(l[id]).to(device) for l in self.layers]\n",
    "\n",
    "        for k in range(len(self.layers)):\n",
    "            R = tuple(random.randint(0, dim) for dim in self.layers[k][id].weight.shape)\n",
    "            #print(\"indices\", k, self.idxs[k])\n",
    "            for i in self.idxs[k]:\n",
    "                ri = random.random()\n",
    "                if ri < self.CR or i == R:\n",
    "                    y[k].weight[i] = self.layers[k][agent_ids[0]].weight[i] + self.F * (self.layers[k][agent_ids[1]].weight[i] - self.layers[k][agent_ids[2]].weight[i])\n",
    "                    #print(\"OUT OF BOUNDS\", id, \"layer \" + str(k) + \" i \" + str(i))\n",
    "                else:\n",
    "                    y[k].weight[i] = self.layers[k][id].weight[i]\n",
    "            #self.print_id(id, y[k].weight)\n",
    "        \n",
    "        fy = L(self.forward_i(X, y), Y)\n",
    "        if fy <= fx: \n",
    "            for k in range(len(self.layers)):\n",
    "                self.layers[k][id] = y[k]\n",
    "            return fy\n",
    "        #self.print_id(id, fy)\n",
    "        return fx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 0.22198030352592468 max 2.294090986251831 avg 0.9450842409991147\n",
      "min 0.19093219935894012 max 1.9912303686141968 avg 0.8549477637148974\n",
      "min 0.19093219935894012 max 1.9912303686141968 avg 0.7533473863025729\n",
      "min 0.19093219935894012 max 1.9912303686141968 avg 0.6932411632511053\n",
      "min 0.19093219935894012 max 1.8236595392227173 avg 0.6566605018765739\n",
      "min 0.19093219935894012 max 1.628330945968628 avg 0.6188687712288974\n",
      "min 0.19093219935894012 max 1.628330945968628 avg 0.5976691480433003\n",
      "min 0.19093219935894012 max 1.628330945968628 avg 0.5903782881377788\n",
      "min 0.16734735667705536 max 1.628330945968628 avg 0.5814126909114001\n",
      "min 0.16734735667705536 max 1.5849899053573608 avg 0.5576640124736207\n",
      "min 0.16734735667705536 max 1.316042423248291 avg 0.5259204704440041\n",
      "min 0.16734735667705536 max 1.316042423248291 avg 0.4993716225530324\n",
      "min 0.16734735667705536 max 1.316042423248291 avg 0.4985275159725982\n",
      "min 0.16734735667705536 max 1.316042423248291 avg 0.4913923561238171\n",
      "min 0.16734735667705536 max 1.316042423248291 avg 0.4913923561238171\n",
      "min 0.16734735667705536 max 1.316042423248291 avg 0.4913923561238171\n",
      "min 0.16734735667705536 max 1.316042423248291 avg 0.4899547771456536\n",
      "min 0.14773201942443848 max 1.316042423248291 avg 0.48606596351339576\n",
      "min 0.14773201942443848 max 1.316042423248291 avg 0.4836416992913471\n",
      "min 0.14773201942443848 max 1.316042423248291 avg 0.482967869786734\n",
      "min 0.14773201942443848 max 1.316042423248291 avg 0.47991577477267616\n",
      "min 0.14773201942443848 max 1.316042423248291 avg 0.4741876743147882\n",
      "min 0.14773201942443848 max 1.316042423248291 avg 0.47379683728298444\n",
      "min 0.09498780965805054 max 1.316042423248291 avg 0.465829400868898\n",
      "min 0.09498780965805054 max 1.316042423248291 avg 0.4642448224378436\n",
      "min 0.09498780965805054 max 1.316042423248291 avg 0.4503136411141814\n",
      "min 0.09498780965805054 max 1.316042423248291 avg 0.4447452362333791\n",
      "min 0.09498780965805054 max 1.316042423248291 avg 0.4367867765131961\n",
      "min 0.09498780965805054 max 1.316042423248291 avg 0.4320231508672907\n",
      "min 0.09498780965805054 max 1.316042423248291 avg 0.42827375049001715\n",
      "min 0.09498780965805054 max 1.294574499130249 avg 0.42803253785947737\n",
      "min 0.09498780965805054 max 1.294574499130249 avg 0.4271496738610643\n",
      "min 0.09498780965805054 max 1.294574499130249 avg 0.41689850021614117\n",
      "min 0.09498780965805054 max 1.294574499130249 avg 0.4140836551283183\n",
      "min 0.09498780965805054 max 1.294574499130249 avg 0.4140836551283183\n",
      "min 0.09498780965805054 max 1.294574499130249 avg 0.41290296681141586\n",
      "min 0.09498780965805054 max 1.294574499130249 avg 0.4068159387352761\n",
      "min 0.09498780965805054 max 1.294574499130249 avg 0.3891240986210577\n",
      "min 0.09498780965805054 max 1.294574499130249 avg 0.3891240986210577\n",
      "min 0.09498780965805054 max 1.294574499130249 avg 0.3779593249050419\n",
      "min 0.09498780965805054 max 1.294574499130249 avg 0.37691089226288743\n",
      "min 0.09498780965805054 max 1.294574499130249 avg 0.37691089226288743\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.3703060265672341\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.3687830636005723\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.3687830636005723\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.3682086380679956\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.3668339553843723\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.36498172648167343\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.36492804144875385\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.36458921884552814\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.36458921884552814\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.36417014093211525\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.36324355860104723\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.36324355860104723\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.3589172214269638\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.35764756112286217\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.35434091074413127\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.35434091074413127\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.35434091074413127\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.3532628331626399\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.3532628331626399\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.3524098799804623\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.3524098799804623\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.34893364467647636\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.34727564236421266\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.34660278026307567\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.34660278026307567\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.34660278026307567\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.3434076444821411\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.34338951127582723\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.34227987772293306\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.33987134443909933\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.33987134443909933\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.33431416147210624\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.33429371339551517\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.33429371339551517\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.33429371339551517\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.33429371339551517\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.33429371339551517\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.33429371339551517\n",
      "min 0.09498780965805054 max 1.2297879457473755 avg 0.33429371339551517\n",
      "min 0.09498780965805054 max 0.8346405625343323 avg 0.3278212937411298\n",
      "min 0.09498780965805054 max 0.8346405625343323 avg 0.3278212937411298\n",
      "min 0.09498780965805054 max 0.8346405625343323 avg 0.32469880748330876\n",
      "min 0.09498780965805054 max 0.8346405625343323 avg 0.319666092817703\n",
      "min 0.09498780965805054 max 0.8346405625343323 avg 0.3158695910418971\n",
      "min 0.09498780965805054 max 0.8346405625343323 avg 0.3143428947483556\n",
      "min 0.09498780965805054 max 0.8346405625343323 avg 0.31432651753505964\n",
      "min 0.09498780965805054 max 0.8346405625343323 avg 0.31432651753505964\n",
      "min 0.09498780965805054 max 0.8346405625343323 avg 0.31267170775472447\n",
      "min 0.09498780965805054 max 0.8346405625343323 avg 0.31267170775472447\n",
      "min 0.09498780965805054 max 0.8346405625343323 avg 0.31267170775472447\n",
      "min 0.09498780965805054 max 0.8346405625343323 avg 0.3123494508895981\n",
      "min 0.09498780965805054 max 0.8346405625343323 avg 0.31201573084579426\n",
      "min 0.09498780965805054 max 0.7753360271453857 avg 0.30644412472676696\n",
      "min 0.09498780965805054 max 0.7753360271453857 avg 0.3056309258335092\n",
      "min 0.09498780965805054 max 0.7753360271453857 avg 0.3056309258335092\n",
      "min 0.09498780965805054 max 0.7753360271453857 avg 0.3056309258335092\n",
      "min 0.09498780965805054 max 0.7753360271453857 avg 0.3056309258335092\n",
      "min 0.09498780965805054 max 0.7753360271453857 avg 0.3045086134015844\n"
     ]
    }
   ],
   "source": [
    "import torch.profiler\n",
    "\n",
    "# 890 models or random candidates\n",
    "# update individual parameters pi, 1 <= i <= 89 using unravel index but on each of the layers....\n",
    "# \n",
    "\n",
    "epochs = 100\n",
    "\n",
    "X = torch.randn(4000, 1).to(device)\n",
    "Y = gaussian_mixture(X).to(device)\n",
    "\n",
    "num_params = 89 #sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "NP = num_params\n",
    "CR = 0.9\n",
    "F = 0.8\n",
    "\n",
    "model = DE_NN(NP, CR, F).to(device)\n",
    "L = nn.MSELoss().to(device)\n",
    "\n",
    "#with torch.autograd.profiler.profile(use_device='cuda') as prof:\n",
    "for e in range(epochs):\n",
    "    #for model in models:\n",
    "    with torch.no_grad():\n",
    "        f_lst = []\n",
    "        for i in range(model.NP):\n",
    "            f_lst.append(model.step(i, X, Y, L).item())\n",
    "        print(\"min\", min(f_lst), \"max\", max(f_lst), \"avg\", mean(f_lst))\n",
    "            \n",
    "        \n",
    "            #print(f\"Epoch [{e+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "            #print(torch.cuda.utilization())\n",
    "            #free, total = torch.cuda.mem_get_info(device)\n",
    "            #mem_used_MB = (total - free) / 1024 ** 2\n",
    "            #print(mem_used_MB)\n",
    "            #print(torch.cuda.memory_summary())\n",
    "    #nvidia-smi -lms 100 --query-gpu=index,gpu_name,memory.total,memory.used,memory.free,temperature.gpu,pstate,utilization.gpu,utilization.memory --format=csv\n",
    "\n",
    "#print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "#prof.export_chrome_trace(\"trace_with_grad_GPU.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [DE_NN] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m test_X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m      2\u001b[0m test_Y \u001b[38;5;241m=\u001b[39m gaussian_mixture(test_X)\n\u001b[1;32m----> 3\u001b[0m model_Y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_X\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m model_Y \u001b[38;5;241m=\u001b[39m model_Y\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\projects\\realtime-nn\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\projects\\realtime-nn\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\User\\Desktop\\projects\\realtime-nn\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:397\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Define the computation performed at every call.\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] is missing the required \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m function\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    399\u001b[0m     )\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Module [DE_NN] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "test_X = torch.linspace(-1, 3, 1000)\n",
    "test_Y = gaussian_mixture(test_X)\n",
    "model_Y = model(test_X.reshape(-1, 1).to(device))\n",
    "model_Y = model_Y.cpu()\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_X.numpy(), test_Y.numpy(), label='Gaussian Mixture')\n",
    "plt.plot(test_X.numpy(), model_Y.detach().numpy(), label='Predictions', color='red', linestyle='dotted')\n",
    "plt.title('Gaussian Mixture Plot')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
